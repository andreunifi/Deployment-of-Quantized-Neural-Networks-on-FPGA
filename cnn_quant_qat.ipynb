{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxtWjuunwymNPFbNZpRzHD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreunifi/Deployment-of-Quantized-Neural-Networks-on-FPGA/blob/main/cnn_quant_qat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install brevitas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdXh7zvTmFc0",
        "outputId": "bc4c7675-f8e2-44aa-dfea-84e393fd6147"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: brevitas in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: dependencies==2.0.1 in /usr/local/lib/python3.11/dist-packages (from brevitas) (2.0.1)\n",
            "Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.11/dist-packages (from brevitas) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from brevitas) (24.2)\n",
            "Requirement already satisfied: setuptools<70.0 in /usr/local/lib/python3.11/dist-packages (from brevitas) (69.5.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from brevitas) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from brevitas) (2.6.0+cu124)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from brevitas) (4.13.2)\n",
            "Requirement already satisfied: unfoldNd in /usr/local/lib/python3.11/dist-packages (from brevitas) (0.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->brevitas) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->brevitas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->brevitas) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "G-bfavOOj0Dz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Brevitas imports\n",
        "from brevitas.nn import QuantConv2d, QuantLinear, QuantReLU, QuantIdentity\n",
        "from brevitas.quant import Int8ActPerTensorFixedPoint, Int8WeightPerTensorFixedPoint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 1\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "metadata": {
        "id": "hu_34iZOlo8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8d7a4c-c67b-4598-bed3-3f313926a0f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:12<00:00, 13.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantized CNN\n",
        "class QuantCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantCNN, self).__init__()\n",
        "        bit_width = 8\n",
        "        self.quant_input = QuantIdentity(act_quant=Int8ActPerTensorFixedPoint, bit_width=bit_width, return_quant_tensor=True)\n",
        "        self.relu = QuantReLU(act_quant=Int8ActPerTensorFixedPoint, bit_width=bit_width, return_quant_tensor=True)\n",
        "\n",
        "        self.conv1 = QuantConv2d(3, 32, 3, padding=1, weight_quant=Int8WeightPerTensorFixedPoint)\n",
        "        self.conv2 = QuantConv2d(32, 64, 3, padding=1, weight_quant=Int8WeightPerTensorFixedPoint)\n",
        "        self.conv3 = QuantConv2d(64, 128, 3, padding=1, weight_quant=Int8WeightPerTensorFixedPoint)\n",
        "        self.conv4 = QuantConv2d(128, 256, 3, padding=1, weight_quant=Int8WeightPerTensorFixedPoint)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "        self._get_flatten_size()\n",
        "\n",
        "        self.fc1 = QuantLinear(self.flatten_size, 256, weight_quant=Int8WeightPerTensorFixedPoint)\n",
        "\n",
        "        self.fc2 = QuantLinear(256, 128, weight_quant=Int8WeightPerTensorFixedPoint)\n",
        "\n",
        "        self.fc3 = QuantLinear(128, 10, weight_quant=Int8WeightPerTensorFixedPoint)\n",
        "\n",
        "    def _get_flatten_size(self):\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 3, 32, 32)\n",
        "            dummy = self.pool(self.relu(self.conv1(dummy)))\n",
        "            dummy = self.pool(self.relu(self.conv2(dummy)))\n",
        "            dummy = self.pool(self.relu(self.conv3(dummy)))\n",
        "            dummy = self.pool(self.relu(self.conv4(dummy)))\n",
        "            self.flatten_size = dummy.view(1, -1).size(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant_input(x)\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = self.pool(self.relu(self.conv4(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(self.relu(self.fc1(x)))\n",
        "        x = self.dropout(self.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = QuantCNN().to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluation\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for _ in range(10)]\n",
        "    n_class_samples = [0 for _ in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if label == pred:\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc:.2f} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh26KVMdls_m",
        "outputId": "799d5cd9-8f0e-47e4-88eb-1a6b148a3350",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_tensor.py:1624: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /pytorch/c10/core/TensorImpl.h:1935.)\n",
            "  return super().rename(names)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:549: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:316.)\n",
            "  return F.conv2d(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [2000/12500], Loss: 2.2887\n",
            "Epoch [1/1], Step [4000/12500], Loss: 2.3322\n",
            "Epoch [1/1], Step [6000/12500], Loss: 2.3153\n",
            "Epoch [1/1], Step [8000/12500], Loss: 2.3122\n",
            "Epoch [1/1], Step [10000/12500], Loss: 2.3013\n",
            "Epoch [1/1], Step [12000/12500], Loss: 2.2923\n",
            "Finished Training\n",
            "Accuracy of the network: 11.36 %\n",
            "Accuracy of plane: 42.30 %\n",
            "Accuracy of car: 0.50 %\n",
            "Accuracy of bird: 0.70 %\n",
            "Accuracy of cat: 6.30 %\n",
            "Accuracy of deer: 1.20 %\n",
            "Accuracy of dog: 31.10 %\n",
            "Accuracy of frog: 3.60 %\n",
            "Accuracy of horse: 2.40 %\n",
            "Accuracy of ship: 4.50 %\n",
            "Accuracy of truck: 21.00 %\n"
          ]
        }
      ]
    }
  ]
}